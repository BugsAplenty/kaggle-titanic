{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic - A Kaggle Submission\n",
    "## By Michael Neiman"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Data Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_test = pd.read_csv('titanic_test.csv', header=0)\n",
    "X_train = pd.read_csv('titanic_train.csv', header=0)\n",
    "y_train = X_train.pop('survived')\n",
    "y_train = pd.to_numeric(y_train, errors='coerce')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preprocessing\n",
    "\n",
    "Let's first create copies of the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Create copies of the data:\n",
    "X_train_preprocessed = X_train.copy()\n",
    "X_test_preprocessed = X_test.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Dropping Irrelevant or hard to use data:\n",
    "\n",
    "We will remove the following columns:\n",
    "- passenger_id\n",
    "- name\n",
    "- ticket\n",
    "- cabin (might use later)\n",
    "- embarked\n",
    "- boat (might use later)\n",
    "- home.dest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def drop_irrelevant_columns(df: pd.DataFrame):\n",
    "    df.drop(['passenger_id', 'name', 'ticket', 'cabin', 'embarked', 'boat', 'home.dest'], axis=1)\n",
    "    return df\n",
    "\n",
    "X_test_preprocessed = X_test_preprocessed.drop(columns = ['passenger_id', 'name', 'ticket', 'cabin', 'embarked', 'boat', 'home.dest'])\n",
    "X_train_preprocessed = X_train_preprocessed.drop(columns = ['passenger_id', 'name', 'ticket', 'cabin', 'embarked', 'boat', 'home.dest'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Using an ordinal encoder on the \"sex\" column:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "s = (X_train_preprocessed.dtypes == 'object')\n",
    "cat_cols = list(s[s].index)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_train_preprocessed[cat_cols] = ordinal_encoder.fit_transform(X_train_preprocessed[cat_cols])\n",
    "X_test_preprocessed[cat_cols] = ordinal_encoder.transform(X_test_preprocessed[cat_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4. Replacing the \"body\" variable:\n",
    "\n",
    "The order of the bodies bears no significance and might hinder the performance of our model. Thus, we change it to \"1\" if a number exists and \"0\" if it doesn't."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misha\\AppData\\Local\\Temp\\ipykernel_25388\\1515864050.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['body'][X['body'].notna()] = 1\n",
      "C:\\Users\\misha\\AppData\\Local\\Temp\\ipykernel_25388\\1515864050.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['body'][X['body'].isna()] = 0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_body(data: pd.DataFrame):\n",
    "    data['body'][data['body'].notna()] = 1\n",
    "    data['body'][data['body'].isna()] = 0\n",
    "    return data\n",
    "\n",
    "X_train_preprocessed = preprocess_body(X_train_preprocessed)\n",
    "X_test_preprocessed = preprocess_body(X_test_preprocessed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 1.4. Imputing columns with missing data and mark the rows as such:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_train_preprocessed.columns\n",
    "                     if X_train_preprocessed[col].isnull().any()]\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    X_train_preprocessed[col + '_was_missing'] = X_train_preprocessed[col].isnull()\n",
    "    X_test_preprocessed[col + '_was_missing'] = X_test_preprocessed[col].isnull()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer()\n",
    "X_train_imputed = pd.DataFrame(imp.fit_transform(X_train_preprocessed))\n",
    "X_test_imputed = pd.DataFrame(imp.fit_transform(X_test_preprocessed))\n",
    "\n",
    "X_train_imputed.columns = X_train_preprocessed.columns\n",
    "X_test_imputed.columns = X_test_preprocessed.columns\n",
    "\n",
    "X_train_preprocessed = X_train_imputed\n",
    "X_test_preprocessed = X_test_imputed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5. Scaling the numeric data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler= StandardScaler().fit(pd.concat([X_train_preprocessed, X_test_preprocessed], axis=0))\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_preprocessed), columns=X_train_preprocessed.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_preprocessed), columns=X_test_preprocessed.columns)\n",
    "\n",
    "X_train_preprocessed = X_train_scaled\n",
    "X_test_preprocessed = X_test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Training and Evaluation.\n",
    "\n",
    "Now let's try some ML techniques which we've encountered:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Preparing the validation data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train_preprocessed, y_train, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Training the data on some different classifiers:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regressor = LogisticRegression(random_state=0).fit(X_train_preprocessed, y_train)\n",
    "xgb_classifier = XGBClassifier(random_state=0).fit(X_train_preprocessed, y_train)\n",
    "tree_classifier = DecisionTreeClassifier(random_state=0).fit(X_train_preprocessed, y_train)\n",
    "random_forest_classifier = RandomForestClassifier(random_state=0).fit(X_train_preprocessed, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Assessing the cross-validation score of each model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:28:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:28:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "F:\\Anaconda3\\envs\\Titanic\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:28:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:28:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logistic: [0.81512605 0.82352941 0.70588235 0.79831933 0.75630252]\n",
      "xgb: [0.79831933 0.82352941 0.69747899 0.80672269 0.72268908]\n",
      "tree: [0.73109244 0.79831933 0.65546218 0.79831933 0.68067227]\n",
      "random forest: [0.79831933 0.85714286 0.74789916 0.8487395  0.73109244]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score_logistic = cross_val_score(logistic_regressor, X_train_split, y_train_split)\n",
    "score_xgb = cross_val_score(xgb_classifier, X_train_split, y_train_split)\n",
    "score_tree = cross_val_score(tree_classifier, X_train_split, y_train_split)\n",
    "score_random_forest = cross_val_score(random_forest_classifier, X_train_split, y_train_split)\n",
    "\n",
    "print(f\"logistic: {score_logistic}\")\n",
    "print(f\"xgb: {score_xgb}\")\n",
    "print(f\"tree: {score_tree}\")\n",
    "print(f\"random forest: {score_random_forest}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}